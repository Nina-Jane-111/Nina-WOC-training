name: Pipeline CI
on:
  # Triggers when 'Create Infrastructure' finishes
  workflow_run:
    workflows: ["Create Infrastructure"]
    types:
      - completed
  # Optional: Manual trigger for testing
  workflow_dispatch:

permissions:
  id-token: write # Required for Azure OIDC login
  contents: read # Required to checkout code
  actions: read # Required to download artifacts

jobs:
  Linter:
    # Only run if the infra workflow succeeded
    if: ${{ github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch' }}
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./src/azure-blob
    steps:
      - name: Get code
        uses: actions/checkout@v4
      - name: Install dependencies
        run: npm install
      - name: Run ESLint
        run: npx eslint .

  UnitTestsSonarQube:
    runs-on: ubuntu-latest
    needs: Linter
    # Only run if Linter passed AND the infra workflow succeeded
    if: ${{ always() && (github.event.workflow_run.conclusion == 'success' || github.event_name == 'workflow_dispatch') }}
    defaults:
      run:
        working-directory: ./src/azure-blob
    steps:
      - name: Get code
        uses: actions/checkout@v4

      # 1. Download the artifact from the 'Create Infrastructure' run
      - name: Download Infra Config
        uses: actions/download-artifact@v4
        with:
          name: infra-config
          path: .
          merge-multiple: true # This prevents it from creating an extra 'infra-config' folder
          github-token: ${{ secrets.GITHUB_TOKEN }}
          # This ID specifically targets the infrastructure run that triggered this CI
          run-id: ${{ github.event.workflow_run.id }}

      - name: Install dependencies
        run: npm install

      # 2. Use the values from the artifact instead of GitHub secrets
      - name: Run tests with Coverage
        run: |
          if [ -f "../../infra.env" ]; then
            echo "Success: infra.env found in local directory."
            export $(grep -v '^#' ../../infra.env | xargs)
            npm test
          else
            echo "Error: infra.env still not found!"
            ls -la # Show hidden files in current directory
            exit 1
          fi
        env:
          PORT: 3000

      - name: SonarQube Scan
        uses: SonarSource/sonarqube-scan-action@master
        with:
          projectBaseDir: src/azure-blob
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

  Deploy:
    runs-on: ubuntu-latest
    needs: UnitTestsSonarQube
    # Add this line to ensure the job starts in the project root
    defaults:
      run:
        working-directory: .
    steps:
      - name: Get code
        uses: actions/checkout@v4

      - name: Download Infra Config
        uses: actions/download-artifact@v4
        with:
          name: infra-config
          path: .
          merge-multiple: true # Prevent the extra 'infra-config' folder
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}

      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Build & Push
        run: |
          export $(grep -v '^#' infra.env | xargs)
          # 1. Push the image
          az acr login --name filevaultregistry01
          docker build -t filevaultregistry01.azurecr.io/file-vault-app:latest ./src/azure-blob
          docker push filevaultregistry01.azurecr.io/file-vault-app:latest

      # Create the Cloud "Folder" (File Share) if it doesn't exist
      - name: Create Azure File Share
        run: |
          export $(grep -v '^#' infra.env | xargs)
          # Ensure this is one continuous line
          az storage share create --name prometheus-config --account-name $AZURE_STORAGE_ACCOUNT_NAME --account-key $AZURE_STORAGE_ACCOUNT_KEY

      # Upload your local prometheus.yml to that Cloud Folder
      - name: Upload Prometheus Config
        run: |
          export $(grep -v '^#' infra.env | xargs)
          az storage file upload \
            --share-name prometheus-config \
            --source ./prometheus.yml \
            --account-name $AZURE_STORAGE_ACCOUNT_NAME \
            --account-key $AZURE_STORAGE_ACCOUNT_KEY

      - name: Deploy Monitoring Stack
        run: |
          # Load the values from the artifact
          export $(grep -v '^#' infra.env | xargs)

          # Get ACR credentials dynamically
          ACR_USERNAME=$(az acr credential show --name filevaultregistry01 --query "username" -o tsv)
          ACR_PASSWORD=$(az acr credential show --name filevaultregistry01 --query "passwords[0].value" -o tsv)

          # Fill in the YAML template with real values
          sed -i "s|<REGISTRY_NAME>|filevaultregistry01|g" monitoring-stack.yaml
          sed -i "s|<REGISTRY_USERNAME>|$ACR_USERNAME|g" monitoring-stack.yaml
          sed -i "s|<REGISTRY_PASSWORD>|$ACR_PASSWORD|g" monitoring-stack.yaml
          sed -i "s|<STORAGE_ACCOUNT_NAME>|$AZURE_STORAGE_ACCOUNT_NAME|g" monitoring-stack.yaml
          sed -i "s|<STORAGE_ACCOUNT_KEY>|$AZURE_STORAGE_ACCOUNT_KEY|g" monitoring-stack.yaml

          # Deploy using the completed YAML file
          az container create \
            --resource-group filevault_resource \
            --file monitoring-stack.yaml
